{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asana        \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = asana.Client.access_token('1/1204862582358995:58225b495568b45ac37d588db2fea9a6')\n",
    "\n",
    "# to surpress warnings\n",
    "client.headers = {'Asana-Enable': 'new_goal_memberships','Asana-Enable': \"new_user_task_lists\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a directory to store all the fetch results\n",
    "if not os.path.exists('./fetchedRecords'):\n",
    "    os.makedirs('./fetchedRecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gid': '1204862567026473', 'name': 'My workspace', 'resource_type': 'workspace'}]\n"
     ]
    }
   ],
   "source": [
    "workspaces = list(client.workspaces.find_all())\n",
    "df_workspaces = pd.DataFrame(workspaces)\n",
    "df_workspaces.to_csv('./fetchedRecords/workspaces.csv', index= False)\n",
    "workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Projects in a Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1204862567026473]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the workspace ID for fetching projects\n",
    "df_existedWorkspace = pd.read_csv('./fetchedRecords/workspace.csv')\n",
    "workspaceIDs = list(df_existedWorkspace['gid'])\n",
    "workspaceIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gid': '1204862567620455',\n",
       "  'name': 'Cross-functional project plan',\n",
       "  'resource_type': 'project'}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects = list(client.projects.find_all(workspaceIDs[0]))\n",
    "df_projects = pd.DataFrame(projects)\n",
    "df_projects.to_csv('./fetchedRecords/projects.csv', index= False)\n",
    "projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Sections in a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1204862567620455]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the project ID for fetching sections and tasks\n",
    "df_existedProjects = pd.read_csv('./fetchedRecords/projects.csv')\n",
    "projectIDs = list(df_existedProjects['gid'])\n",
    "projectIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gid': '1204862567620456', 'name': 'To do', 'resource_type': 'section'},\n",
       " {'gid': '1204862567620458', 'name': 'Doing', 'resource_type': 'section'},\n",
       " {'gid': '1204862567620459', 'name': 'Done', 'resource_type': 'section'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections = list(client.sections.find_by_project(projectIDs[0]))\n",
    "df_sections = pd.DataFrame(sections)\n",
    "df_sections.to_csv('./fetchedRecords/sections.csv', index= False)\n",
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Tasks in a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching only modifies tasks (optimized approach) \n",
    "\n",
    "current_datetime = datetime.utcnow().isoformat()\n",
    "\n",
    "try: # file exists ==> some etl has already performed \n",
    "    df_tasks = pd.read_csv('./fetchedRecords/tasks.csv') # Assumed that file is always present\n",
    "    # print(f'Previous df\\n{df_tasks}\\n')    \n",
    "except FileNotFoundError: # etl running for the first time \n",
    "    df_tasks = pd.DataFrame(columns=['gid', 'name', 'resource_type', 'resource_subtype', 'etl_date_created', 'etl_date_modified'])\n",
    "    past_date = datetime(2000, 1, 1, 00, 00, 0000)\n",
    "    last_modified = past_date.strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "else:\n",
    "    last_modified = df_tasks['etl_date_modified'].max()\n",
    "\n",
    "tasks = client.tasks.find_by_project(projectIDs[0], modified_since=last_modified)\n",
    "df_modifiedTasks = pd.DataFrame(tasks)\n",
    "    \n",
    "if len(df_modifiedTasks) == 0: # if no records are modifed since last_modified date \n",
    "    print('No modified records!!!')    \n",
    "else:\n",
    "    df_tasks['gid'] = df_tasks['gid'].astype(str)\n",
    "    df_tasks = df_tasks[~df_tasks['gid'].isin(df_modifiedTasks['gid'])]\n",
    "\n",
    "    # Adding etl_date_created and etl_date_modified columns in fetched df\n",
    "    df_modifiedTasks['etl_date_modified'] = current_datetime\n",
    "    df_modifiedTasks = df_modifiedTasks.merge(df_tasks[['gid', 'etl_date_created']], on='gid', how='left')\n",
    "    df_modifiedTasks['etl_date_created'].fillna(current_datetime, inplace=True)\n",
    "    # print(f'processed fetched df\\n{df_modifiedTasks}\\n')\n",
    "\n",
    "    # merging the two dfs\n",
    "    df_updatedTasks = pd.concat([df_tasks, df_modifiedTasks]).drop_duplicates(subset='gid', keep='last')\n",
    "    # print(f'final df\\n{df_updatedTasks}\\n')\n",
    "           \n",
    "    df_updatedTasks.to_csv(f'./fetchedRecords/tasks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching task details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No modified records!!!\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.utcnow().isoformat()\n",
    "\n",
    "df_tasks = pd.read_csv('./fetchedRecords/tasks.csv')\n",
    "tasksDetails_list = []\n",
    "\n",
    "try: # file exists ==> some etl has already performed \n",
    "    df_existedTaskDetails = pd.read_csv('./fetchedRecords/taskDetails.csv') # Assumed that file is always present\n",
    "    # print(f'Previous df\\n{df_existedTaskDetails}\\n')    \n",
    "except FileNotFoundError: # etl running for the first time \n",
    "    # getting gids of all tasks \n",
    "    gids_tasksToFetch = list(df_tasks['gid'])\n",
    "    df_existedTaskDetails = pd.DataFrame(columns=['gid','etl_date_created', 'etl_date_modified'])\n",
    "else:\n",
    "    # getting the gids of tasks which are modifed after taskDetail etl previous run\n",
    "    df_taskAndTaskDetails = pd.merge(df_tasks, df_existedTaskDetails, on='gid', how = 'left', suffixes=('_df1', '_df2'))\n",
    "\n",
    "    gids_modifiedTasks = list(df_taskAndTaskDetails[df_taskAndTaskDetails['etl_date_modified_df1'] > df_taskAndTaskDetails['etl_date_modified_df2']]['gid'])\n",
    "    gids_newTasks = list(df_taskAndTaskDetails[df_taskAndTaskDetails['etl_date_modified_df2'].isnull()]['gid'])\n",
    "\n",
    "    gids_tasksToFetch = gids_modifiedTasks + gids_newTasks  \n",
    "\n",
    "if len(gids_tasksToFetch) == 0:\n",
    "    print('No modified records!!!')\n",
    "else:\n",
    "    df_tasks['gid'] = df_tasks['gid'].astype(str)\n",
    "    df_existedTaskDetails['gid'] = df_existedTaskDetails['gid'].astype(str)\n",
    "   \n",
    "    # calling API for the modified task details only\n",
    "    for task_gid in gids_tasksToFetch:\n",
    "        task = client.tasks.get_task(str(task_gid))\n",
    "        tasksDetails_list.append(task)\n",
    "    df_newTaskDetails = pd.DataFrame(tasksDetails_list)\n",
    "\n",
    "    # Adding etl_date_created and etl_date_modified columns in fetched df\n",
    "    df_newTaskDetails['etl_date_modified'] = current_datetime\n",
    "    df_newTaskDetails = df_newTaskDetails.merge(df_existedTaskDetails[['gid', 'etl_date_created']], on='gid', how='left')\n",
    "    df_newTaskDetails['etl_date_created'].fillna(current_datetime, inplace=True)    \n",
    "    # print(f'processed fetched df\\n{df_modifiedTasks.head()}\\n')\n",
    "\n",
    "    # merging the two dfs\n",
    "    df_updatedTaskDetails = pd.concat([df_existedTaskDetails, df_newTaskDetails]).drop_duplicates(subset='gid', keep='last')\n",
    "    # print(f'final df\\n{df_updatedTaskDetails.head()}\\n')\n",
    "     \n",
    "    df_updatedTaskDetails.to_csv(f'./fetchedRecords/taskDetails.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
