{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json           \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"authorization\": \"Bearer 1/1204862582358995:58225b495568b45ac37d588db2fea9a6\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asanaResToCSV(csvName, res):\n",
    "    '''\n",
    "        csvName: name of csv file in which data to dump\n",
    "        res: response of the asana api\n",
    "    '''\n",
    "    resDict = json.loads(res.text) # String to dict\n",
    "    df = pd.DataFrame.from_dict(resDict['data'])\n",
    "    if not os.path.exists('./fetchedRecords'):\n",
    "        os.makedirs('./fetchedRecords')\n",
    "    df.to_csv(f'./fetchedRecords/{csvName}.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = \"https://app.asana.com/api/1.0/workspaces\"\n",
    "resWorkspace = requests.get(workspace, headers=headers)\n",
    "# print(resWorkspace.text) # type ==> 'dict' \n",
    "asanaResToCSV('workspace', resWorkspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = \"https://app.asana.com/api/1.0/projects\"\n",
    "resProjects = requests.get(projects, headers=headers)\n",
    "# print((resProjects.text)) # type ==> 'dict' \n",
    "asanaResToCSV('projects', resProjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the project ID for fetching sections and tasks\n",
    "resProjectsDict = json.loads(resProjects.text)\n",
    "projectID = resProjectsDict['data'][0]['gid']\n",
    "# print(projectID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = f\"https://app.asana.com/api/1.0/tasks?project={projectID}\"\n",
    "resTasks = requests.get(tasks, headers=headers)\n",
    "# print((resTasks.text)) # type ==> 'dict' \n",
    "asanaResToCSV('tasks', resTasks)\n",
    "\n",
    "current_datetime = datetime.utcnow().isoformat()\n",
    "encoded_datetime = urllib.parse.quote(current_datetime)\n",
    "\n",
    "try: # file exists ==> some etl has already performed \n",
    "    df_tasks = pd.read_csv('./fetchedRecords/tasks.csv') # Assumed that file is always present\n",
    "    # print(f'Previous df\\n{df_tasks}\\n')\n",
    "    last_modified = df_tasks['etl_date_modified'].max()\n",
    "except FileNotFoundError: # etl running for the first time \n",
    "    df_tasks = pd.DataFrame(columns=['gid', 'name', 'resource_type', 'resource_subtype', 'etl_date_created', 'etl_date_modified'])\n",
    "    past_date = datetime(2000, 1, 1, 00, 00, 0000)\n",
    "    last_modified = past_date.strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "tasks = f\"https://app.asana.com/api/1.0/tasks?project={projectID}&modified_since={last_modified}\"\n",
    "resTasks = requests.get(tasks, headers=headers) \n",
    "resDict = json.loads(resTasks.text) # String to dict\n",
    "df_modifiedTasks = pd.DataFrame.from_dict(resDict['data'])\n",
    "# print(f'fetched df\\n{df_modifiedTasks}\\n')\n",
    "    \n",
    "if len(df_modifiedTasks) == 0: # No records are modifed \n",
    "    # print('No modified records!!!')    \n",
    "    pass\n",
    "else:\n",
    "    df_tasks['gid'] = df_tasks['gid'].astype(str)\n",
    "\n",
    "    # Adding etl_date_created and etl_date_modified columns in fetched df\n",
    "    df_modifiedTasks['etl_date_modified'] = encoded_datetime\n",
    "    df_modifiedTasks = df_modifiedTasks.merge(df_tasks[['gid', 'etl_date_created']], on='gid', how='left')\n",
    "    df_modifiedTasks['etl_date_created'].fillna(encoded_datetime, inplace=True)\n",
    "    # print(f'processed fetched df\\n{df_modifiedTasks}\\n')\n",
    "\n",
    "    # merging the two dfs\n",
    "    df_merged = pd.concat([df_tasks, df_modifiedTasks]).drop_duplicates(subset='gid', keep='last')\n",
    "    # print(f'final df\\n{df_merged}\\n')\n",
    "\n",
    "    if not os.path.exists('./fetchedRecords'):\n",
    "        os.makedirs('./fetchedRecords')        \n",
    "    df_merged.to_csv(f'./fetchedRecords/tasks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tasks = pd.read_csv('./fetchedRecords/tasks.csv')\n",
    "tasksDetails_list = []\n",
    "for task_gid in df_tasks['gid']:\n",
    "    task = f\"https://app.asana.com/api/1.0/tasks/{task_gid}\"\n",
    "    resTask = requests.get(task, headers=headers)\n",
    "    resDict = json.loads(resTask.text) # String to dict\n",
    "    taskDetails = pd.json_normalize(resDict['data'], max_level=0)\n",
    "    tasksDetails_list.append(taskDetails)\n",
    "df_taskDetails = pd.concat(tasksDetails_list)\n",
    "print(df_taskDetails)\n",
    "\n",
    "if not os.path.exists('./fetchedRecords'):\n",
    "    os.makedirs('./fetchedRecords')\n",
    "df_taskDetails.to_csv(f'./fetchedRecords/taskDetails.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
